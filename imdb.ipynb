{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMREpWUDMscAGMRB0YQUn9u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/tibaml1027/blob/main/imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4totK37TkSvw",
        "outputId": "941bac0a-99b6-4ea5-9929-443b617f37d7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n",
            "84140032/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WMAXTieXmP4B",
        "outputId": "97481bdd-dd1f-446b-853e-a3d5f66b5d91"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/aclImdb.tar.gz'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpWNh_R8kmpD"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "def getdata(mid):\n",
        "    dn = os.path.dirname(dataset)\n",
        "    posfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"pos\", \"*\"))\n",
        "    negfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"neg\", \"*\"))\n",
        "    contents = []\n",
        "    for fn in posfn + negfn:\n",
        "        with open(fn, encoding=\"utf-8\") as f:\n",
        "            contents.append(f.read())\n",
        "    df = pd.DataFrame({\n",
        "        \"content\":contents,\n",
        "        \"sentiment\":[1] * len(posfn) + [0] * len(negfn)\n",
        "    })\n",
        "    return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZY3goAzmBVj"
      },
      "source": [
        "train_df = getdata(\"train\")\n",
        "test_df = getdata(\"test\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pH8FyudNmvXB",
        "outputId": "21f93423-0b9e-4062-8c4d-b5c41ef5f434"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Valentine \"Dogkiller\" Dussaut and Joe \"The Jud...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ruthless mercenary Bruno Rivera (Paul Naschy i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Should we take the opening shot as a strange f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Being a retired medical/health field \"toiler i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I wasn't expecting a great deal from this film...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>I give it a 2, because of the beautiful Medite...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>How bad can you make a film. A good question w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>Oh, my. Oh, this is a *really* bad movie. The ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>Apparently re-cut episodes from the Gangbuster...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>Another winner from that 50s , 60s era that I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 content  sentiment\n",
              "0      Valentine \"Dogkiller\" Dussaut and Joe \"The Jud...          1\n",
              "1      Ruthless mercenary Bruno Rivera (Paul Naschy i...          1\n",
              "2      Should we take the opening shot as a strange f...          1\n",
              "3      Being a retired medical/health field \"toiler i...          1\n",
              "4      I wasn't expecting a great deal from this film...          1\n",
              "...                                                  ...        ...\n",
              "24995  I give it a 2, because of the beautiful Medite...          0\n",
              "24996  How bad can you make a film. A good question w...          0\n",
              "24997  Oh, my. Oh, this is a *really* bad movie. The ...          0\n",
              "24998  Apparently re-cut episodes from the Gangbuster...          0\n",
              "24999  Another winner from that 50s , 60s era that I ...          0\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OND4Chfr0I4"
      },
      "source": [
        "# Tokenize: 把你的詞變成數字\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tok = Tokenizer(num_words=3000)\n",
        "tok.fit_on_texts(train_df[\"content\"])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Py1xzKms5My"
      },
      "source": [
        "# tok.word_index\n",
        "# tok.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M12AkfRWtc4t"
      },
      "source": [
        "# Sequence: 化成數字的序列\n",
        "x_train_seq = tok.texts_to_sequences(train_df[\"content\"])\n",
        "x_test_seq = tok.texts_to_sequences(test_df[\"content\"])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZxiz5DE3UNn"
      },
      "source": [
        "INPUT_LENGTH = 512\n",
        "INPUT_DIM = 3000\n",
        "OUTPUT_DIM = 128"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHDWdjXFtd98"
      },
      "source": [
        "# pd.DataFrame(x_train_seq)\n",
        "# Padding: 截長補短變成一樣長\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train_pad = pad_sequences(x_train_seq, maxlen=INPUT_LENGTH)\n",
        "x_test_pad = pad_sequences(x_test_seq, maxlen=INPUT_LENGTH)\n",
        "pd.DataFrame(x_train_pad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xtHMj-0w4Y"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "layers = [\n",
        "    # 3001(種詞) * 128(個情緒)\n",
        "    Embedding(INPUT_DIM+1, OUTPUT_DIM, mask_zero=True, input_length=INPUT_LENGTH),\n",
        "    Flatten(),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dropout(0.25),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEd1gejs475N",
        "outputId": "46feeb5d-869e-4996-d994-2453d51b5bb1"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "layers = [\n",
        "    # 3001(種詞) * 128(個情緒)\n",
        "    Embedding(INPUT_DIM+1, OUTPUT_DIM, mask_zero=True, input_length=INPUT_LENGTH),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 512, 128)          384128    \n",
            "                                                                 \n",
            " global_average_pooling1d_3   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 384,386\n",
            "Trainable params: 384,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezdWMd9_9NEU"
      },
      "source": [
        "# 一個輸出(二元分類): BinaryCrossEntropy p log 1/q + (1 - p) log 1/1-q\n",
        "# 多個輸出(多元分類): CategoricalCrossEntropy pi log1/qi\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "model.compile(loss=SparseCategoricalCrossentropy(),\n",
        "              # \"adam\"也可以\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyQpS0iy9kKs"
      },
      "source": [
        "import numpy as np\n",
        "y_train = np.array(train_df[\"sentiment\"])\n",
        "y_test = np.array(test_df[\"sentiment\"])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857yYqF79d5e"
      },
      "source": [
        "# batch_size: 看多少筆, 做一次梯度下降(幾10~幾100)\n",
        "# epochs: 所有資料看幾輪(負責結束訓練)\n",
        "# batch_size=200\n",
        "# 一epochs: 54000 / 200 = 270(次梯度下降)\n",
        "# verbose=0(quiet) 1(default) 2(no bar)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"imdb.h5\", save_best_only=True)\n",
        "]\n",
        "model.fit(x_train_pad,\n",
        "          y_train,\n",
        "          batch_size=200,\n",
        "          epochs=100,\n",
        "          validation_split=0.1,\n",
        "          verbose=2,\n",
        "          callbacks=callbacks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWS9Cr_K94OF",
        "outputId": "c39d780e-cf10-42bd-fea2-f658ef30e4b0"
      },
      "source": [
        "model.evaluate(x_test_pad, y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 3ms/step - loss: 0.2936 - accuracy: 0.8814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29357779026031494, 0.8814399838447571]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbc3BJafBrSt"
      },
      "source": [
        "l = [\n",
        "    Embedding(INPUT_DIM+1, OUTPUT_DIM, mask_zero=True)\n",
        "]\n",
        "remain = model.layers[1:]\n",
        "model_use = Sequential(l+remain)\n",
        "model_use.layers[0].set_weights(model.layers[0].get_weights())\n",
        "model_use.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qsZMExpDuVQ",
        "outputId": "fbcc1a55-11ba-46c7-b6cc-1eb71645e940"
      },
      "source": [
        "review = input(\"影評:\")\n",
        "review_seq = tok.texts_to_sequences([review])\n",
        "proba = model_use.predict(review_seq)[0]\n",
        "trans = [\"neg\", \"pos\"]\n",
        "for p, sentiment in zip(proba, trans):\n",
        "    print(sentiment, \":\", p)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "影評:My toes have just about uncurled enough to free me to diss this over-sentimental piece of tosh. There's a fine art, I believe, in concocting a classic Christmas movie, but the best of them - \"It's A Wonderful Life\", \"The Bishop's Wife\", \"Miracle on 34th Street\" etc, all manage it by being natural and unforced, showing real people in real situations, but their lives overtaken in one way or another by that unclassifiable Christmas spirit.  The so-called fare on show here is however so calculated and lacking in good humour (in every sense of the phrase) that what's left is an overwrought, overplayed, overdone piece of contrived hokum.  Quite how an ordinary member of the public is meant to relate to high-flying movie-trailer producer Cameron Diaz in her all mod cons dream house, replete with swimming pool and electric curtains, or publishing executive Jude Law as a grieving widower, Jack Black as a cuckolded movie soundtrack composer or even the most downbeat character, Kate Winslet as a lovelorn journalist but still somehow lives in a picturesque cottage in Surrey, is beyond me. And if the answer to that question is meant to be the persuasive talents of the actors on show, then that's another miss as far as I'm concerned. Diaz gets to wig out as per usual to a rock track (likewise Winslet) and how she can't cry anymore, Law gets to gush stuff and nonsense about his doting kids, Winslet builds up an unbelievable with a decrepit sardonic old Hollywood screenwriter and Black tags after a younger model playing him for a fool, in between composing saccharine music for the big screen. Cue Hans Zimmer's completely bland muzak, which seems to get turned on and up whenever A BIG SCENE arises.  Cringe-worthy scene follows cringe-worthy scene as all ends happily ever after with the final images of the happy couples partying down with as much phony conviction as they can muster.  Really, I could go on and on, but this is about as cynical and hokey as Hollywood gets in going after the big Christmas buck. There are a host of wonderful Christmas movies out there and not just the Golden Age classics I mentioned at the outset - Bill Murray's \"Scrooged\" for one. I haven't seen such a bad film in such a long time and can only recommend that if you decide to watch it, imbibe in a whole lot of Christmas spirits beforehand. Unfortunately, being teetotal, I had no such release and suffered accordingly!\n",
            "neg : 0.64933944\n",
            "pos : 0.35066053\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3Wl3o1vtPdTOW5L+MoxeH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/tibaml1027/blob/main/imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4totK37TkSvw",
        "outputId": "941bac0a-99b6-4ea5-9929-443b617f37d7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 2s 0us/step\n",
            "84140032/84125825 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WMAXTieXmP4B",
        "outputId": "97481bdd-dd1f-446b-853e-a3d5f66b5d91"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/aclImdb.tar.gz'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpWNh_R8kmpD"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "def getdata(mid):\n",
        "    dn = os.path.dirname(dataset)\n",
        "    posfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"pos\", \"*\"))\n",
        "    negfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"neg\", \"*\"))\n",
        "    contents = []\n",
        "    for fn in posfn + negfn:\n",
        "        with open(fn, encoding=\"utf-8\") as f:\n",
        "            contents.append(f.read())\n",
        "    df = pd.DataFrame({\n",
        "        \"content\":contents,\n",
        "        \"sentiment\":[1] * len(posfn) + [0] * len(negfn)\n",
        "    })\n",
        "    return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZY3goAzmBVj"
      },
      "source": [
        "train_df = getdata(\"train\")\n",
        "test_df = getdata(\"test\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "pH8FyudNmvXB",
        "outputId": "21f93423-0b9e-4062-8c4d-b5c41ef5f434"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Valentine \"Dogkiller\" Dussaut and Joe \"The Jud...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ruthless mercenary Bruno Rivera (Paul Naschy i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Should we take the opening shot as a strange f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Being a retired medical/health field \"toiler i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I wasn't expecting a great deal from this film...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>I give it a 2, because of the beautiful Medite...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>How bad can you make a film. A good question w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>Oh, my. Oh, this is a *really* bad movie. The ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>Apparently re-cut episodes from the Gangbuster...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>Another winner from that 50s , 60s era that I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 content  sentiment\n",
              "0      Valentine \"Dogkiller\" Dussaut and Joe \"The Jud...          1\n",
              "1      Ruthless mercenary Bruno Rivera (Paul Naschy i...          1\n",
              "2      Should we take the opening shot as a strange f...          1\n",
              "3      Being a retired medical/health field \"toiler i...          1\n",
              "4      I wasn't expecting a great deal from this film...          1\n",
              "...                                                  ...        ...\n",
              "24995  I give it a 2, because of the beautiful Medite...          0\n",
              "24996  How bad can you make a film. A good question w...          0\n",
              "24997  Oh, my. Oh, this is a *really* bad movie. The ...          0\n",
              "24998  Apparently re-cut episodes from the Gangbuster...          0\n",
              "24999  Another winner from that 50s , 60s era that I ...          0\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OND4Chfr0I4"
      },
      "source": [
        "# Tokenize: 把你的詞變成數字\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tok = Tokenizer(num_words=3000)\n",
        "tok.fit_on_texts(train_df[\"content\"])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Py1xzKms5My"
      },
      "source": [
        "# tok.word_index\n",
        "# tok.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M12AkfRWtc4t"
      },
      "source": [
        "# Sequence: 化成數字的序列\n",
        "x_train_seq = tok.texts_to_sequences(train_df[\"content\"])\n",
        "x_test_seq = tok.texts_to_sequences(test_df[\"content\"])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZxiz5DE3UNn"
      },
      "source": [
        "INPUT_LENGTH = 512\n",
        "INPUT_DIM = 3000\n",
        "OUTPUT_DIM = 128"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHDWdjXFtd98"
      },
      "source": [
        "# pd.DataFrame(x_train_seq)\n",
        "# Padding: 截長補短變成一樣長\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train_pad = pad_sequences(x_train_seq, maxlen=INPUT_LENGTH)\n",
        "x_test_pad = pad_sequences(x_test_seq, maxlen=INPUT_LENGTH)\n",
        "pd.DataFrame(x_train_pad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xtHMj-0w4Y"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "layers = [\n",
        "    # 3001(種詞) * 128(個情緒)\n",
        "    Embedding(INPUT_DIM+1, OUTPUT_DIM, mask_zero=True, input_length=INPUT_LENGTH),\n",
        "    Flatten(),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dropout(0.25),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEd1gejs475N",
        "outputId": "5938ac08-da65-4deb-ea47-77f57cf9844d"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "layers = [\n",
        "    # 3001(種詞) * 128(個情緒)\n",
        "    Embedding(INPUT_DIM+1, OUTPUT_DIM, mask_zero=True, input_length=INPUT_LENGTH),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 512, 128)          384128    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 384,386\n",
            "Trainable params: 384,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}